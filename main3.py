import random
from streamlit_mic_recorder import speech_to_text
import ollama as ol
import requests
import streamlit as st

# æ‰“å°èŠå¤©æ¶ˆæ¯
def print_chat_message(message, ChatTTSServer, audio_seed_input, Audio_temp, Top_P, Top_K, Refine_text, is_history):
    text = message["content"]

    if message["role"] == "user":
        with st.chat_message("user", avatar="ðŸ˜Š"):
            print_txt(text)
    if message["role"] == "assistant":
        with st.chat_message("assistant", avatar="ðŸ¤–"):
            print_txt(text)
            cleartext = text

            if not is_history:
                try:
                    res = requests.post(ChatTTSServer, data={
                        "text": cleartext,
                        "prompt": "",
                        "voice": audio_seed_input,
                        "temperature": Audio_temp,
                        "top_p": Top_P,
                        "top_k": Top_K,
                        "skip_refine": Refine_text,
                        "custom_voice": audio_seed_input,
                        "speed": 5,
                        "refine_max_new_token": 384,
                        "infer_max_new_token": 2048,
                        "text_seed": 42
                    })

                    response_json = res.json()

                    if response_json["code"] == 0:
                        audioURL = response_json["audio_files"][0]["url"]
                        st.audio(audioURL, format="audio/mpeg", autoplay=True, loop=False)
                    else:
                        st.error("ç”ŸæˆéŸ³é¢‘æ—¶å‡ºé”™: " + response_json.get("msg", "æœªçŸ¥é”™è¯¯"))

                except requests.exceptions.RequestException as e:
                    st.error(f"è¯·æ±‚å¤±è´¥: {e}")

# æ‰“å°æ–‡æœ¬å†…å®¹
def print_txt(text):
    st.write(text)

st.set_page_config(layout="wide")

# æ‘„åƒå¤´åŠŸèƒ½
def camera_sidebar():
    st.sidebar.header("Camera Feed")
    camera_image = st.sidebar.camera_input("Capture Image")
    if camera_image:
        st.sidebar.image(camera_image, caption="Captured Image", use_column_width=True)

# å½•éŸ³åŠŸèƒ½
def record_voice(language="zh"):
    state = st.session_state
    if "text_received" not in state:
        state.text_received = []

    text = speech_to_text(
        start_prompt="Click to speak",
        stop_prompt="Stop recording",
        language=language,
        use_container_width=True,
        just_once=True,
    )

    if text:
        state.text_received.append(text)

    result = ""
    for text in state.text_received:
        result += text

    state.text_received = []

    return result if result else None

# ç”Ÿæˆéšæœºç§å­
def generate_seed():
    new_seed = random.randint(1, 100000000)
    st.session_state.Audio_Seed = new_seed

# ç”Ÿæˆæ–‡æœ¬ç§å­
def generate_seed2():
    new_seed = random.randint(1, 100000000)
    st.session_state.Text_Seed = new_seed

# ç”¨æˆ·è¯­è¨€é€‰æ‹©
def language_selector():
    lang_options = ["ar", "de", "en", "es", "fr", "it", "ja", "nl", "pl", "pt", "ru", "zh"]
    return st.selectbox("è¯­è¨€ Language", ["zh"] + lang_options)

# Ollamaæ¨¡åž‹é€‰æ‹©
def OllamaModel():
    ollama_models = [m['name'] for m in ol.list()['models']]
    return st.selectbox("æ¨¡åž‹ Ollama Models", ollama_models)

# OllamaæœåŠ¡å™¨è®¾ç½®
def OllamaServer():
    return st.text_input("Ollama Server URL", "http://127.0.0.1:11434")

# ChatTTSæœåŠ¡å™¨è®¾ç½®
def ChatTTSServer():
    ChatTTSServer = st.text_input("ChatTTS Server URL", "http://127.0.0.1:9966/tts")
    col1, col2 = st.columns(2)
    with col1:
        audio_seed_input = st.number_input("éŸ³è‰² Audio Seed", value=42, key='Audio_Seed')
        st.button(":game_die: Audio Seed", on_click=generate_seed, use_container_width=True)
        Audio_temp = st.slider('è¯­è°ƒ Audio temperature ', min_value=0.01, max_value=1.0, value=0.3, step=0.05, key="Audiotemperature")
        oral_input = st.slider(label="å£è¯­åŒ– Oral", min_value=0, max_value=9, value=2, step=1)
        laugh_input = st.slider(label="ç¬‘å£° Laugh", min_value=0, max_value=2, value=0, step=1)
        Refine_text = st.checkbox("æ ¼å¼åŒ–æ–‡æœ¬ Refine text", value=True, key='Refine_text')
    with col2:
        text_seed_input = st.number_input("Text Seed", value=42, key='Text_Seed')
        st.button(":game_die: Text Seed", on_click=generate_seed2, use_container_width=True)
        Top_P = st.slider('top_P', min_value=0.1, max_value=0.9, value=0.3, step=0.1, key="top_P")
        Top_K = st.slider('top_K', min_value=1, max_value=20, value=20, step=1, key="top_K")
        bk_input = st.slider(label="åœé¡¿ Break", min_value=0, max_value=7, value=4, step=1)
        TTSServer = ChatTTSServer
    return TTSServer, audio_seed_input, Audio_temp, Top_P, Top_K, Refine_text

# ä¸»å‡½æ•°
def main():
    camera_sidebar()

    st.header(':rainbow[:speech_balloon: Ollama V-Chat]')

    with st.container():
        server = OllamaServer()
        model = OllamaModel()
        language = language_selector()

        TTSServer, audio_seed_input, Audio_temp, Top_P, Top_K, Refine_text = ChatTTSServer()

        col1, col2 = st.columns([4, 1])
        with col1:
            text_input = st.text_input('', placeholder="Type here and Enter to send", label_visibility='collapsed', key="text_input_key")
        with col2:
            question = record_voice(language=language)

        with st.container(height=500, border=True):
            if "chat_history" not in st.session_state:
                st.session_state.chat_history = {}
            if model not in st.session_state.chat_history:
                st.session_state.chat_history[model] = []
            chat_history = st.session_state.chat_history[model]
            if len(chat_history) == 0:
                chat_history.append({"role": "system",
                                     "content": "æˆ‘ä¼šç”¨ä¸­æ–‡ç®€çŸ­å›žç­”ã€‚"})

            for message in chat_history:
                print_chat_message(message, TTSServer, st.session_state.Audio_Seed, Audio_temp, Top_P, Top_K, Refine_text, is_history=True)
            if question or text_input:
                user_message = {
                    "role": "user",
                    "content": question or text_input,
                    "ChatTTSServer": TTSServer,
                    "audio_seed_input": st.session_state.Audio_Seed,
                    "Audio_temp": Audio_temp,
                    "Top_P": Top_P,
                    "Top_K": Top_K,
                    "Refine_text": Refine_text,
                }
                print_chat_message(user_message, TTSServer, st.session_state.Audio_Seed, Audio_temp, Top_P, Top_K, Refine_text, is_history=False)
                chat_history.append(user_message)
                response = ol.chat(model=model, messages=chat_history)
                answer = response['message']['content']
                ai_message = {
                    "role": "assistant",
                    "content": answer,
                    "ChatTTSServer": TTSServer,
                    "audio_seed_input": st.session_state.Audio_Seed,
                    "Audio_temp": Audio_temp,
                    "Top_P": Top_P,
                    "Top_K": Top_K,
                    "Refine_text": Refine_text,
                }
                print_chat_message(ai_message, TTSServer, st.session_state.Audio_Seed, Audio_temp, Top_P, Top_K, Refine_text, is_history=False)
                chat_history.append(ai_message)

                if len(chat_history) > 20:
                    chat_history = chat_history[-20:]

                st.session_state.chat_history[model] = chat_history

if __name__ == "__main__":
    main()
